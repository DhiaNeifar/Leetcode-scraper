# ğŸ“˜ LeetCode Scraper

**LeetCode Scraper** is a Python automation tool that logs into your LeetCode account using saved cookies, scrapes your **Accepted** submissions, and saves them locally. The scraped solutions are automatically committed and pushed to a GitHub repository of your choice.

---

## ğŸ”§ Features

- âœ… Scrapes only **Accepted** LeetCode submissions
- âœ… Saves code with clean, descriptive filenames: `0326 - Power of Three.py`
- âœ… Supports multiple languages: `Python3`, `C++`, `C`
- âœ… Avoids duplicates by tracking saved submissions
- âœ… Automatically commits and pushes changes to GitHub
- âœ… **Headless execution** using `xvfb-run` (runs without showing browser windows)
- âœ… Persistent logging: each run generates a new log file saved in the `runs/` folder
- âœ… Setup script handles everything from environment setup to automation

---

## ğŸ§± Motivation

This project was created as a personal alternative to popular but limited/free tools like:

- âŒ LeetHub
- âŒ LeetSync
- âŒ leetcode-cli

These tools either:
- Required third-party authentication and access to your GitHub repositories, or
- Simply did not work as expected in real-world usage.

LeetCode Scraper avoids all of this by:
- Running locally with **zero external dependencies**
- Giving **you full control** over your credentials and repositories
- Being easy to extend, understand, and trust

---

## âš™ï¸ How It Works

### ğŸ”¹ `install.sh` Script

The `install.sh` script is your entrypoint. It:

1. Creates a Python virtual environment (if not already created)
2. Installs all Python dependencies from `requirements.txt`
3. Prompts the user to log into LeetCode manually in Chrome
4. Clones your GitHub repository to store solutions
5. Runs the scraper using `xvfb-run` to hide the browser
6. Commits and pushes new submissions to GitHub
7. Optionally sets up a recurring job using `cron`

### ğŸ”¹ Logging with `runs/`
- All logs are stored under the `runs/` folder
- Each run generates a timestamped log file (e.g., `runs/2025-05-14T21:12:00.log`)
- Make sure `runs/` is in your `.gitignore`

### ğŸ”¹ Cookie Management
- The `utils/cookies.py` script handles exporting and formatting cookies
- Cookies are saved to `leetcode_cookies.xml`
- **Never share this file** â€” it gives full access to your LeetCode account

---

## ğŸš€ Getting Started

### 1. Clone this Repository
```bash
git clone https://github.com/your-username/leetcode-scraper.git
cd leetcode-scraper
```

### 2. Run the Setup Script
```bash
bash setup.sh
```

The script will:
- Set up the environment
- Ask for your GitHub repo URL
- Ask for a GitHub token
- Run the scraper
- Commit and push your submissions to GitHub

---

## ğŸ”‘ Setting Up Your GitHub Token

1. Visit: [GitHub Token Settings](https://github.com/settings/tokens)
2. Click **Generate new token (fine-grained)**
3. Choose the repository you want to give access to
4. Enable permissions:
   - **Contents** â†’ âœ… Read and Write
   - **Metadata** â†’ âœ… Required (default)
5. Copy the token and paste it when `setup.sh` prompts you

> The token is saved to `.scraper_config` and is **not shared with anyone**

---

## ğŸ§  How It Works Internally

### ğŸ”¸ `main.py`
- Parses the folder where submissions will be saved
- Loads cookies and invokes the `LeetCodeScraper` class

### ğŸ”¸ `utils/scraper.py`
- Uses Selenium and ChromeDriver to browse LeetCode
- Visits `/submissions/`, parses each row, extracts accepted solutions
- Downloads code using `submissionCode` and saves it in the repo folder
- Tracks `(problem_id, language)` pairs to avoid duplicates
- Stops when it hits a submission older than `.lastscraped`

### ğŸ”¸ `.scraper_config`
This file saves:
- Your GitHub repo URL
- Your personal GitHub token

### ğŸ”¸ `.lastscraped`
- Stores the timestamp of the most recent scrape
- Ensures next run only scrapes *newer* submissions

---

## â±ï¸ Automating Scrapes with `cron`
After running `setup.sh`, you can choose to auto-run the scraper every X minutes/hours/days.

### Example Prompt:
```bash
ğŸ• Run how often? Choose: [m]inutes, [h]ours, [d]ays: h
Enter frequency number (e.g., every 2 hours = 2): 2
```
This sets up a `cron` job to run the scraper **every 2 hours**.

### ğŸ”» How to View or Remove Cron Jobs
```bash
crontab -l       # Show all cron jobs
crontab -e       # Edit cron jobs (delete the scraper line to stop it)
```

> Cron jobs wonâ€™t run while your machine is off. They resume on next uptime.

---

## ğŸ“ Output
Submissions are saved under your GitHub repo in this format:
```
0326 - Power of Three.py
0697 - Degree of an Array.cpp
```

They are committed and pushed automatically.

---

## ğŸ“¦ Dependencies
```
selenium
webdriver-manager
undetected-chromedriver
```

---

## ğŸ”’ Security Reminder
- Do NOT commit your `leetcode_cookies.xml` file
- Make sure your `.gitignore` includes:
```
leetcode_cookies.xml
.scraper_config
runs/
```

---

## ğŸ“„ License
MIT License
